{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ytzvKHiNJxD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Rescaling\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "data_dir"
      ],
      "metadata": {
        "id": "zmZPE0nbbshP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557d63ce-53cd-4738-fe7f-1073f93f992c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets/flower_photos')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jttvOY1vBKUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a767ee1b-4966-41f1-bad8-369633d02b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 620\n",
            "drwx------ 2 270850 5000  36864 Feb 10  2016 daisy\n",
            "drwx------ 2 270850 5000  45056 Feb 10  2016 dandelion\n",
            "-rw-r----- 1 270850 5000 418049 Feb  9  2016 LICENSE.txt\n",
            "drwx------ 2 270850 5000  36864 Feb 10  2016 roses\n",
            "drwx------ 2 270850 5000  36864 Feb 10  2016 sunflowers\n",
            "drwx------ 2 270850 5000  45056 Feb 10  2016 tulips\n"
          ]
        }
      ],
      "source": [
        "!ls -l /root/.keras/datasets/flower_photos/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5utdaHqqMzA6",
        "outputId": "c5ba2bef-8f81-49a9-825f-dd2c5639022d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "633\n",
            "898\n",
            "898\n",
            "641\n",
            "699\n"
          ]
        }
      ],
      "source": [
        "!ls -l /root/.keras/datasets/flower_photos/daisy | grep jpg | wc -l\n",
        "!ls -l /root/.keras/datasets/flower_photos/dandelion | grep jpg | wc -l\n",
        "!ls -l /root/.keras/datasets/flower_photos/dandelion | grep jpg | wc -l\n",
        "!ls -l /root/.keras/datasets/flower_photos/roses | grep jpg | wc -l\n",
        "!ls -l /root/.keras/datasets/flower_photos/sunflowers | grep jpg | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hhbzupcNJxG"
      },
      "outputs": [],
      "source": [
        "# Image path define\n",
        "daisy_path = '/root/.keras/datasets/flower_photos/daisy/'\n",
        "dandelion_path = '/root/.keras/datasets/flower_photos/dandelion/'\n",
        "roses_path = '/root/.keras/datasets/flower_photos/roses/'\n",
        "sunflowers_path = '/root/.keras/datasets/flower_photos/sunflowers/'\n",
        "tulips_path = '/root/.keras/datasets/flower_photos/tulips/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Images lists\n",
        "daisy_file = os.listdir(daisy_path)\n",
        "dandelion_file = os.listdir(dandelion_path)\n",
        "roses_file = os.listdir(roses_path)\n",
        "sunflowers_file = os.listdir(sunflowers_path)\n",
        "tulips_file = os.listdir(tulips_path)"
      ],
      "metadata": {
        "id": "oYJoqvZlwcdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Image lists\n",
        "#daisy_file[:2], roses_file[:2]"
      ],
      "metadata": {
        "id": "tabF3y11wcgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check images and drawing two sets images\n",
        "for img_file in daisy_file[:2] :\n",
        "    img = Image.open(daisy_path + img_file).resize((224,224))\n",
        "    plt.title(img_file + ' : Positive')\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "for img_file in roses_file[:2] :\n",
        "    img = Image.open(roses_path + img_file).resize((224,224))\n",
        "    plt.title(img_file + ' : Negative')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "T1gnYZq2xQZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label define : class\n",
        "\n",
        "class2idx = {'daisy' :  0, 'dandelion' : 1,  'roses' : 2, 'sunflowers' : 3, 'tulips' : 4}\n",
        "idx2class = {0 : 'daisy', 1 : 'dandelion', 2 : 'roses', 3 : 'sunflowers', 4 : 'tulips'}\n"
      ],
      "metadata": {
        "id": "QUuTY8xuxQcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data and label manually\n",
        "\n",
        "img_list = []\n",
        "label_list = []\n",
        "\n",
        "daisy_file = os.listdir(daisy_path)\n",
        "for img_file in daisy_file :\n",
        "  img = Image.open(daisy_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # scaling\n",
        "  img_list.append(img)\n",
        "  label_list.append(0) # daisy : 0\n",
        "\n",
        "dandelion_file = os.listdir(dandelion_path)\n",
        "for img_file in dandelion_file :\n",
        "  img = Image.open(dandelion_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # scaling\n",
        "  img_list.append(img)\n",
        "  label_list.append(1) # dandelion : 1\n",
        "\n",
        "roses_file = os.listdir(roses_path)\n",
        "for img_file in roses_file :\n",
        "  img = Image.open(roses_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # scaling\n",
        "  img_list.append(img)\n",
        "  label_list.append(2) # roses : 2\n",
        "\n",
        "sunflowers_file = os.listdir(sunflowers_path)\n",
        "for img_file in sunflowers_file :\n",
        "  img = Image.open(sunflowers_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # scaling\n",
        "  img_list.append(img)\n",
        "  label_list.append(3) # sunflowers : 3\n",
        "\n",
        "tulips_file = os.listdir(tulips_path)\n",
        "for img_file in tulips_file :\n",
        "  img = Image.open(tulips_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # scaling\n",
        "  img_list.append(img)\n",
        "  label_list.append(4) # tulips : 4"
      ],
      "metadata": {
        "id": "R9LP9xaAxQfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image data, label to numpy array\n",
        "img_list_arr =  np.array(img_list)\n",
        "label_list_arr = np.array(label_list)"
      ],
      "metadata": {
        "id": "KoZ5n3O-4B8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check shape of data, label\n",
        "img_list_arr.shape, label_list_arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0JP-95RxQiI",
        "outputId": "2cd59b98-221c-49f9-f3e1-0d56a89cbac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3670, 128, 128, 3), (3670,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test , y_train, y_test = train_test_split(img_list_arr, label_list_arr,\n",
        "                                                     test_size=0.3, stratify=label_list_arr, random_state=41)\n",
        "X_train.shape, X_test.shape , y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peFBw_Xr2fJi",
        "outputId": "8894f05a-57bf-42cc-b17e-f45353eb7645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2569, 128, 128, 3), (1101, 128, 128, 3), (2569,), (1101,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build - Hyperparameter Tunning\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.5\n",
        "input_shape = (128, 128, 3) #check shape"
      ],
      "metadata": {
        "id": "P_oEqqET4iWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME5cAZwSNJyE"
      },
      "outputs": [],
      "source": [
        "# Modeling\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Conv2D(32, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
        "#model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Conv2D(32, kernel_size=5,activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(64,(2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A6EKt5RLNlZ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', #tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='sparse_categorical_crossentropy', # why sparse - Loss Function\n",
        "              metrics=['accuracy'])  # Metrics / Accuracy\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12V92LSdBKU5"
      },
      "outputs": [],
      "source": [
        "# callback : EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "mc = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC0e4z1Fo4lU"
      },
      "outputs": [],
      "source": [
        "# num_epochs = 10, # batch_size = 32\n",
        "# training\n",
        "history = model.fit(X_train, y_train ,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[es, mc]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC0t0RBWLNlb",
        "outputId": "e5f27681-4010-4e59-abb3-71ef5cee8ebb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY9uRhr2LNlc"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqmH37cABKU6"
      },
      "outputs": [],
      "source": [
        "# Predict using Test data\n",
        "i=1\n",
        "plt.figure(figsize=(16, 8))\n",
        "for img, label in zip(X_test[:8], y_test[:8]):\n",
        "      # predict\n",
        "      pred = model.predict(img.reshape(-1,128, 128, 3))\n",
        "      pred_t = np.argmax(pred)\n",
        "      plt.subplot(2, 4, i)\n",
        "      plt.title(f'True Value:{label}, Pred Value: {pred_t}')\n",
        "      plt.imshow(img)\n",
        "      plt.axis('off')\n",
        "      i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Rescaling\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "data_dir\n",
        "\n",
        "!ls -l /root/.keras/datasets/flower_photos/\n",
        "\n",
        "#check fiel and draw sample image\n",
        "daisy_file = os.listdir(daisy_path)\n",
        "daisy_file[:2]\n",
        "\n",
        "for img_file in daisy_file[:2] :\n",
        "    img = Image.open(daisy_path + img_file).resize((224,224))\n",
        "    plt.title(img_file + ' : Positive')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XxPRLvxdhWXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi0QpDAd1EeX",
        "outputId": "5c00b1a5-12ce-4e06-9ed8-1af4d409b817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3670 files belonging to 5 classes.\n",
            "Using 2936 files for training.\n",
            "Found 3670 files belonging to 5 classes.\n",
            "Using 734 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# image_dataset_from_directory\n",
        "# - onehot encoding labeling - image deployment - shuffle\n",
        "# hyper params\n",
        "input_shape = (224, 224, 3)\n",
        "batch_size = 32\n",
        "num_classes = 5\n",
        "\n",
        "#image path\n",
        "img_path ='/root/.keras/datasets/flower_photos/'\n",
        "\n",
        "# train dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                             directory=img_path,\n",
        "                                             label_mode=\"categorical\",   # binary , categorical\n",
        "                                             batch_size=batch_size,\n",
        "                                             image_size=(224, 224),      # input shape\n",
        "                                             seed=42,\n",
        "                                             shuffle=True,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset=\"training\"    # \"training\"/\"validation\". Only used if validation_split is set.\n",
        "                                            )\n",
        "\n",
        "# test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                             directory=img_path,\n",
        "                                             label_mode=\"categorical\",   # binary , categorical\n",
        "                                             batch_size=batch_size,\n",
        "                                             image_size=(224, 224),      # input shape\n",
        "                                             seed=42,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset=\"validation\"\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUI7yk4Q8vkU",
        "outputId": "81387838-0844-48b3-9257-486d56134ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# check class name\n",
        "train_ds.class_names #train_ds.element_spec\n",
        "# check total data. batch_size = 32\n",
        "# len(train_ds) * 32 , len(test_ds) * 32\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#batch_img, batch_label = next(iter(train_ds))\n",
        "#batch_img.shape, batch_label.shape\n",
        "\n",
        "# check Image\n",
        "#batch_img, batch_label = next(iter(train_ds))\n",
        "#image = batch_img[0]  # Get a single image\n",
        "#plt.imshow(image/255)\n",
        "#plt.show()\n",
        "#print(batch_label[0])  # View the image's label\n",
        "\n",
        "# check sample image\n",
        "i = 0\n",
        "for batch_img, batch_label in train_ds.take(1): #take(1) get one from batch. take(32) get 32 from batch\n",
        "  if i == 0 :\n",
        "    print(batch_img[i].shape)\n",
        "    plt.imshow(batch_img[i]/255)\n",
        "  i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#modeling\n",
        "# Hyperparameter Tunning\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.5\n",
        "\n",
        "input_shape = (224, 224, 3)  # check size\n",
        "num_classes = 5"
      ],
      "metadata": {
        "id": "Jr2mrgZsLXDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Rescaling(1. / 255))  # 이미지 Rescaling. 없이 하면 성능이 안나옴.\n",
        "model.add(Conv2D(32, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Conv2D(64,(2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
        "              loss='categorical_crossentropy',  # Loss Function\n",
        "              metrics=['accuracy'])  # Metrics / Accuracy\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7VYPeZY5gtot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk1OAl7I8vkW"
      },
      "outputs": [],
      "source": [
        "# EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "mc = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5-WLRiiJ4wn"
      },
      "outputs": [],
      "source": [
        "# image_dataset_from_directory, then go ahead\n",
        "# num_epochs = 10\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=(test_ds),\n",
        "                    epochs=10,\n",
        "                    callbacks=[es, mc]\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e1dbad-ffd4-4e98-da1f-d04d7372891f",
        "id": "gN7Ucx_-J4wn"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuINNqKTJ4wn"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict trial\n",
        "batch_img , batch_label = next(iter(test_ds))\n",
        "batch_img.shape, batch_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wacfLnnKdUDH",
        "outputId": "31bf931b-8530-437c-80aa-6844ff4f4a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 224, 224, 3]), TensorShape([32, 224, 224, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfviSuTCV3lG"
      },
      "outputs": [],
      "source": [
        "# predict - performance\n",
        "\n",
        "i = 1\n",
        "plt.figure(figsize=(16, 30))\n",
        "for img, label in list(zip(batch_img, batch_label)):\n",
        "    pred = model.predict(img.numpy().reshape(-1, 224,224,3), verbose=0)\n",
        "    pred_t = np.argmax(pred)\n",
        "    plt.subplot(8, 4, i)\n",
        "    plt.title(f'True Value:{np.argmax(label)}, Pred Value: {pred_t}')\n",
        "    plt.imshow(img/255)  # Image pixeles are float, so make values 0~1\n",
        "    i = i + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "a18HnMX2nT2p"
      },
      "outputs": [],
      "source": [
        "## MobileNet Transfer Learning & Fine-tuning\n",
        "# Keras applicatioins list-up\n",
        "dir(tf.keras.applications)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLOQS08knT2q"
      },
      "outputs": [],
      "source": [
        "# Pre-trained MobileNetV2 to base model\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    weights='imagenet',\n",
        "    include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "H68s7B-2nT2q"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.applications.MobileNetV2 models needs [-1, 1] pixel value, not [0, 255]\n",
        "# Need to be reshaped for MobileNetV2 [-1, 1]\n",
        "# There are two ways to process\n",
        "# 1- preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "# 2- rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
      ],
      "metadata": {
        "id": "k7Q7KjLp1zlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEB31BKynT2q"
      },
      "outputs": [],
      "source": [
        "# MobileNet V2 base model - grounding\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescaling # functional\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = tf.keras.layers.Rescaling(1./127.5, offset=-1)(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "# shrink from 3-dimension (7, 7, 1280) --to-> 1-dimension (1280) using GlobalAveragePooling2D\n",
        "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "bdiUC8jv3c7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz5rJF9V0vAc"
      },
      "outputs": [],
      "source": [
        "# model compile\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
        "              loss='categorical_crossentropy',  # Loss Function\n",
        "              metrics=['accuracy'])             # Metrics / Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0dIeYzznT2q"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "# ModelCheckpoint\n",
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32FA-d9FnT2r"
      },
      "outputs": [],
      "source": [
        "# image_dataset_from_directory\n",
        "# num_epochs = 10 # batch_size = 32\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data = test_ds,\n",
        "    epochs=2,\n",
        "    callbacks=[es, checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45611113-9436-4561-f5c7-4e19ddc54537",
        "id": "oaKgRoyf0vAd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgVVTLE_0vAd"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqDSUZLKLNlc",
        "outputId": "82bacd5a-2832-4711-8cf6-c17026623cbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32, 5)\n"
          ]
        }
      ],
      "source": [
        "# Get test_generator sample\n",
        "# batch_size = 32\n",
        "batch_img, batch_label = next(iter(test_ds))\n",
        "print(batch_img.shape)\n",
        "print(batch_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srDpKfQTnT2s",
        "outputId": "5d1d3cf9-a8e9-4f38-f151-e8e793f31181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
              "array([[ 96.     , 152.21428, 203.64285],\n",
              "       [ 94.71429, 153.64285, 206.     ],\n",
              "       [ 94.21429, 153.85715, 208.     ],\n",
              "       [ 97.5    , 151.     , 207.5    ],\n",
              "       [ 96.14285, 150.92857, 207.     ],\n",
              "       [ 92.57143, 151.85715, 207.78572],\n",
              "       [ 93.14285, 149.57143, 209.42857],\n",
              "       [ 96.42857, 153.64285, 207.57143],\n",
              "       [ 98.     , 156.     , 206.     ],\n",
              "       [ 95.85714, 155.92857, 210.14285]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# image rescale\n",
        "batch_img[0][0][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8QJbl6RnT2s"
      },
      "outputs": [],
      "source": [
        "# 100% accuracy\n",
        "i = 1\n",
        "plt.figure(figsize=(16, 30))\n",
        "for img, label in list(zip(batch_img, batch_label)):\n",
        "    pred = model.predict(img.numpy().reshape(-1, 224,224,3), verbose=0)\n",
        "    pred_t = np.argmax(pred)\n",
        "    plt.subplot(8, 4, i)\n",
        "    plt.title(f'True Value:{np.argmax(label)}, Pred Value: {pred_t}')\n",
        "    plt.imshow(img/255)  # values are need to be range(0~1) avoiding error\n",
        "    i = i + 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}